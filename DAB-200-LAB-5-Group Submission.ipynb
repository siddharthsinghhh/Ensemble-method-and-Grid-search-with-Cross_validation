{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lab 5 # Ensemble method and Grid search with Cross_validation .\n",
    "\n",
    "Group members:\n",
    "- Name (ID): Sai Sahas Elluru (0753808)\n",
    "- Name (ID): Hari Sai Palem (0747511)\n",
    "- Name (ID): Siddharth Singh (0756590)\n",
    "\n",
    "In this lab, the main objective is to understand the parameters of the Decision Tree model and how to evaluate the model based on the different metrics we studied.\n",
    "\n",
    "By the end of this lab you should have:\n",
    "\n",
    "- a good understanding of ensemble of Decision Trees.\n",
    "- learn and implement how grid search and cross validation are combined in the GridsearchCV class."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Grading\n",
    "\n",
    "This lab will be graded as follows:\n",
    "- 50% for comments/text\n",
    "    - Half of the lab grade will come from an assessment of the comments/text included in your Jupyter notebook submission\n",
    "        - The comments/text should explain clearly what you are doing and why it's necessary to achieve the objective\n",
    "        - You should think of the comments/text as if you were creating a tutorial/blog to guide someone through your work \n",
    "- 50% for code\n",
    "    - Half of the lab grade will come from an assessment of your code\n",
    "        - The code in the notebook should use base python, NumPy, Pandas, sklearn, and/or matplotlib. \n",
    "        - All code cells should run error free\n",
    "        - The code does not have to be optimized or pretty: it needs to be functional for the specific task"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Submition\n",
    "\n",
    "This is a **group submission** lab, so work in the same groups that you are already assigned to.\n",
    "\n",
    "You should submit the following:\n",
    "- a well-commented Jupyter notebook\n",
    "- the original dataset used as a .csv file"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Instructions\n",
    "Use the same dataset that you used for the marked lab #4. If your dataset is bigger than 1,000 rows, you can truncate the dataset to only 1,000 rows to avoid CPU performance issues and explain how you performed the cut.\n",
    "\n",
    "Make sure to explain your steps, results and observations at each step.\n",
    "\n",
    "Use the last 3 digits from any of your group team members user ID as a random state variable where applicable and do implement the following:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1- Using nested loops and split ratio 65_training, 15_validation, and 20_testing; while using only the training and validation sets build a random forest with number of trees between 5 and 12 with a step of 2 using the default parameters and implement a cross-validation with 4 folds. Ensure to print out the validation score for each fold and find the one that provides the best accuracy.\n",
    "\n",
    "Once you have identified the one with the best accuracy above, evaulate the accuracy of this model using the testing_set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import cross_val_score\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "import required libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[WinError 3] The system cannot find the path specified: 'E:\\\\Clair\\\\SEM2\\\\ML\\\\LAb3'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-88-b5f06267cf9d>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mos\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mchdir\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'E:\\\\Clair\\\\SEM2\\\\ML\\\\LAb3'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [WinError 3] The system cannot find the path specified: 'E:\\\\Clair\\\\SEM2\\\\ML\\\\LAb3'"
     ]
    }
   ],
   "source": [
    "import os\n",
    "os.chdir('E:\\\\Clair\\\\SEM2\\\\ML\\\\LAb3')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('baseball.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using pandas import baseball.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Team</th>\n",
       "      <th>League</th>\n",
       "      <th>Year</th>\n",
       "      <th>RS</th>\n",
       "      <th>RA</th>\n",
       "      <th>W</th>\n",
       "      <th>OBP</th>\n",
       "      <th>SLG</th>\n",
       "      <th>BA</th>\n",
       "      <th>Playoffs</th>\n",
       "      <th>RankSeason</th>\n",
       "      <th>RankPlayoffs</th>\n",
       "      <th>G</th>\n",
       "      <th>OOBP</th>\n",
       "      <th>OSLG</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ARI</td>\n",
       "      <td>NL</td>\n",
       "      <td>2012</td>\n",
       "      <td>734</td>\n",
       "      <td>688</td>\n",
       "      <td>81</td>\n",
       "      <td>0.328</td>\n",
       "      <td>0.418</td>\n",
       "      <td>0.259</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>162</td>\n",
       "      <td>0.317</td>\n",
       "      <td>0.415</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ATL</td>\n",
       "      <td>NL</td>\n",
       "      <td>2012</td>\n",
       "      <td>700</td>\n",
       "      <td>600</td>\n",
       "      <td>94</td>\n",
       "      <td>0.320</td>\n",
       "      <td>0.389</td>\n",
       "      <td>0.247</td>\n",
       "      <td>1</td>\n",
       "      <td>4.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>162</td>\n",
       "      <td>0.306</td>\n",
       "      <td>0.378</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>BAL</td>\n",
       "      <td>AL</td>\n",
       "      <td>2012</td>\n",
       "      <td>712</td>\n",
       "      <td>705</td>\n",
       "      <td>93</td>\n",
       "      <td>0.311</td>\n",
       "      <td>0.417</td>\n",
       "      <td>0.247</td>\n",
       "      <td>1</td>\n",
       "      <td>5.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>162</td>\n",
       "      <td>0.315</td>\n",
       "      <td>0.403</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>BOS</td>\n",
       "      <td>AL</td>\n",
       "      <td>2012</td>\n",
       "      <td>734</td>\n",
       "      <td>806</td>\n",
       "      <td>69</td>\n",
       "      <td>0.315</td>\n",
       "      <td>0.415</td>\n",
       "      <td>0.260</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>162</td>\n",
       "      <td>0.331</td>\n",
       "      <td>0.428</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>CHC</td>\n",
       "      <td>NL</td>\n",
       "      <td>2012</td>\n",
       "      <td>613</td>\n",
       "      <td>759</td>\n",
       "      <td>61</td>\n",
       "      <td>0.302</td>\n",
       "      <td>0.378</td>\n",
       "      <td>0.240</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>162</td>\n",
       "      <td>0.335</td>\n",
       "      <td>0.424</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Team League  Year   RS   RA   W    OBP    SLG     BA  Playoffs  RankSeason  \\\n",
       "0  ARI     NL  2012  734  688  81  0.328  0.418  0.259         0         NaN   \n",
       "1  ATL     NL  2012  700  600  94  0.320  0.389  0.247         1         4.0   \n",
       "2  BAL     AL  2012  712  705  93  0.311  0.417  0.247         1         5.0   \n",
       "3  BOS     AL  2012  734  806  69  0.315  0.415  0.260         0         NaN   \n",
       "4  CHC     NL  2012  613  759  61  0.302  0.378  0.240         0         NaN   \n",
       "\n",
       "   RankPlayoffs    G   OOBP   OSLG  \n",
       "0           NaN  162  0.317  0.415  \n",
       "1           5.0  162  0.306  0.378  \n",
       "2           4.0  162  0.315  0.403  \n",
       "3           NaN  162  0.331  0.428  \n",
       "4           NaN  162  0.335  0.424  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data1 = data[0:1000]\n",
    "data1.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Trimming the data to 1000 values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "data2 = data1[['RS','RA','W','OBP','SLG','BA','G','League','Playoffs']]\n",
    "data3 = data2.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RS          0\n",
       "RA          0\n",
       "W           0\n",
       "OBP         0\n",
       "SLG         0\n",
       "BA          0\n",
       "G           0\n",
       "Playoffs    0\n",
       "NL          0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dummies = pd.get_dummies(data3.League,drop_first=True)\n",
    "data4 = pd.concat([data3,dummies],axis=1)\n",
    "data_final = data4.drop('League',axis=1)\n",
    "data_final.head()\n",
    "data_final.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Storing the required columns into the variable 'data'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = data_final.Playoffs.values\n",
    "x = data_final.drop('Playoffs',axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Store the feature variables in x and target variable in y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, test_df, y_train, y_test = train_test_split(x, y,test_size=.2, random_state=590)\n",
    "train_df, val_df, train_target, y_val = train_test_split(X_train,y_train,test_size = .1875, random_state=590)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now using train test split from sklearn, split the data into training, testing and validating datasets.\n",
    "\n",
    "In the first statement, we are splitting the data (x, y) into test_df, y_test and X_train, y_train with the test_size = 0.2. Now we have testing datset with 20% of the data.\n",
    "\n",
    "In the second statement, we are splitting the data (X_train, y_train) into train_df, y_train and val_df, y_val with the test_size = 0.1875. Now we have validation dataset with 15% of the data.\n",
    "\n",
    "train_df -> training dataset = 65%\n",
    "\n",
    "test_df -> testing dataset = 20%\n",
    "\n",
    "val_df -> validation dataset = 15%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of points in train data 650\n",
      "number of points in validation data 150\n",
      "number of points in test 200\n"
     ]
    }
   ],
   "source": [
    "print('number of points in train data', train_df.shape[0])\n",
    "print('number of points in validation data', val_df.shape[0])\n",
    "print('number of points in test', test_df.shape[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Checking the shape each dataset train_df, test_df, and val_df."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ensemble learning is used to enhance the performance of Machine Learning model. Random Forest comes under bagging technique. In bagging, weak learners are produced parallely in training phase. Performance of model can be increased by parallely training the weak learners on a bootstrap dataset. Dividing the dataset into bootstrapped datasets and running weak learner algorithm on each of the bootstrapped datasets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cross val score for n_estimator =  5 is 0.89625\n",
      "\n",
      "cross val score for n_estimator =  7 is 0.905\n",
      "\n",
      "cross val score for n_estimator =  9 is 0.9125000000000001\n",
      "\n",
      "cross val score for n_estimator =  11 is 0.9125000000000001\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "for i in [5,7,9,11]:\n",
    "    clf_RF = RandomForestClassifier(n_estimators = i, random_state = 590)\n",
    "    scores=cross_val_score(clf_RF,X_train,y_train,cv=4).mean()\n",
    "    print(\"cross val score for n_estimator = \", i, \"is\", scores)\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using sklearn ensemble we import Randomforest classifier to create a new model. Random forest also works as decision tree but RF consturcts multiple decision trees by changing the root node. That means each time a tree is built with different root node and decision nodes. Each tree gives the final decision or leaf node. RF chooses the result of majority of the decision trees.\n",
    "Here n_estimators means number of trees to be built.\n",
    "\n",
    "Cross validation score is calculated using taget, feature, model and number of folds. Generally, cross validation shuffles the data randomly and split the data into given number of folds. Using the data provided it splits,train, and evaluates for each fold.\n",
    "\n",
    "Now we are using for loop to calculate which estimator gives the best cross val score and model. And the classifier is random forest classifier. Calculating cross val score which is imported from sklearn. The parameters are randomforest classifier and validation dataset and 4 folds. Calculating the mean of each fold for each estimators. \n",
    "\n",
    "Randomforest classifier model gives best cross validation score with the estimator = 9 which is 0.913."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "#print('accuracy for 5,7,9,11 trees are',acc[0:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.885"
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_RF = RandomForestClassifier(n_estimators = 9)\n",
    "model_RF.fit(X_train,y_train)\n",
    "y_pred_test_set = model_RF.predict(test_df)\n",
    "accuracy_score(y_test,y_pred_test_set)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using the best estimator which we got by calculating the cross validation score, we build the random forest model and fit it using training data. Then predict the values for testing data and calculate the prediction accuracy or testing accuracy.\n",
    "\n",
    "Testing accuracy for randomforest clssifier with 9 trees is 0.84"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2- Explain the difference between the best accuracy obtained from the model and that obtained using the testing_set above.\n",
    "\n",
    "Compare your results in Step#1 above to the best results you had in lab #4, explain the differencies if any."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Best accuracy from the cross validation score is 0.906 by building random forest classifier with 9 trees. And testing accuracy of random forest classifier with 9 trees is 0.84. There is a huge difference between these 2 accuracies.\n",
    "Generally to estimate the performance of the model we have to consider the test accuracy. The accuracy for validation set could be more because of overfitting. And moreover the model behaves differently with the unseen data (test) than the data which is used to train the model. This can be the reason for less testing accuracy.\n",
    "\n",
    "Tesiting accuracy for decision tree model with same data is 0.9 and for RF model is 0.84. Decision tree builts a single tree with respect to decrease the entropy in the dataset. But a single decision tree is often a weak learner. We need multiple trees for better prediction. These multiple trees method is Random forest classifier method. Though the testing accuracy of random forest is less than testing accuracy of decision tree, the prediction for random forest is better. And the other reason would be data used for training the data in the case of decision tree is 80% and the training data used in random forest is 65%.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3- Similar to question 1 in lab #4 but instead of using nested loops use the GridSearchCV class with the model that you obtained in step 1 above, try to find the best combined parameters that provide the best accuracy for the testing dataset from:\n",
    "- max_depth values between 3 and 5 with a step of 1.\n",
    "- max_leaf_nodes values between 10 and 20 with a step of 5.\n",
    "- min_samples_leaf with values between 10 and 25 with a step of 5.\n",
    "\n",
    "Plot your results for the testing and training accuracies for each step.\n",
    "\n",
    "\n",
    "Compare your result with what you obtained in lab #4."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "params= {'max_depth': (3,4,5),\n",
    "        'max_leaf_nodes':(10,15,20),\n",
    "        'min_samples_leaf':(10,15,20,25)}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "max_depth, max_leaf_nodes and min_samples_leaf are the parameters which we are tuning. Params is the variable for the grid search parameter param_grid."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "dt = RandomForestClassifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test score is 0.87\n",
      "Best parameters:{'max_depth': 5, 'max_leaf_nodes': 10, 'min_samples_leaf': 25}\n",
      "Best grid search score:0.925\n",
      "Best estimator:RandomForestClassifier(max_depth=5, max_leaf_nodes=10, min_samples_leaf=25,\n",
      "                       n_estimators=9, random_state=590)\n"
     ]
    }
   ],
   "source": [
    "grid_search_RF = GridSearchCV(RandomForestClassifier(n_estimators=9,random_state=590), param_grid = params,return_train_score=True,scoring = 'accuracy', n_jobs = -1)\n",
    "grid_search_RF = grid_search_RF.fit(X_train, y_train)\n",
    "accuracy = grid_search_RF.best_score_\n",
    "print(\"Test score is \"+str(grid_search_RF.score(test_df,y_test)))\n",
    "print(\"Best parameters:\"+str(grid_search_RF.best_params_))\n",
    "print(\"Best grid search score:\"+str(accuracy))\n",
    "print(\"Best estimator:\"+str(grid_search_RF.best_estimator_))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we using grid search cv which is an library fo r hyperparameter tuning.\n",
    "Each parameter of decission tree classifier has significance. Max depth represents how many layers does a tree need to spread. If max_depth is higher then there is a high chance of overfitting vice versa if it is lower then there is a chance that the tree not recognize the importance of features. Over here we are comparing max_depth of 3 and 4 we take 3 as our ideal since it lead to high accuracy.\n",
    "\n",
    "max_leaf_nodes determines the tree with max_leaf_nodes in best first fashion. Best nodes are defined as relative reduction in impurity. So we will go for higher max_leaf_nodes. By that condition for max_leaf_node 10 the accuracy is higher.\n",
    "\n",
    "min_sample_leaf: leaf node is a node without any children(without any further splits). This value used to stop split of leafs to certain samples. This reduces overfitting and complexity. By this condition for min_sample_leaf 25 the accuracy is higher.\n",
    "\n",
    "So for the combination max_depth:3, max_leaf_nodes:15, and min_sample_leaf:10 the testing accuracy is 0.925.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "            dt_RF = RandomForestClassifier(n_estimators = 9, max_depth = 5, max_leaf_nodes = 10, min_samples_leaf = 25, random_state = 590)\n",
    "            dt_RF.fit(X_train, y_train)  #fit the model\n",
    "            y_pred = dt_RF.predict(test_df)\n",
    "            testaccuracy_RF = accuracy_score(y_test,y_pred)  \n",
    "            \n",
    "            y_pred2 = dt_RF.predict(X_train)\n",
    "            trainaccuracy_RF = accuracy_score(y_train,y_pred2)\n",
    "            \n",
    "            objects_RF = ('Test Accuracy_RF', 'Train Accuracy_RF')\n",
    "            y = np.arange(len(objects_RF))\n",
    "            Accuracy_RF = [testaccuracy_RF, trainaccuracy_RF]\n",
    "            plt.bar(y, Accuracy_RF, width = 0.6, align = 'center', alpha=0.4, color = ['red', 'green'])\n",
    "            for index, value in enumerate(Accuracy_RF): \n",
    "                plt.text(index, value, str(value), horizontalalignment='center', verticalalignment='top', alpha = 1.0)\n",
    "            plt.xticks(y, objects_RF)\n",
    "            plt.ylabel('Accuracies')\n",
    "            plt.title('Accuracy Plot')\n",
    "            plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using the model with best parameters, we are predicting the values for test_df and finding the predicting accuracy. And also predicting the values for train_df and finding the predicting accuracy for training set. And also we plotted the training and testing accuracies. Obviously, the training accuracy will be higher because the model has already seen the training data which we used to fit the model with. To validate the model performance we need to consider the prediction accuracy of test data which is .\n",
    "\n",
    "The prediction accuracy of test data for decision tree model with the parameters max_depth:3, max_leaf_nodes:15, and min_sample_leaf:10 is 0.9.\n",
    "\n",
    "The prediction accuracy of test data for Random forest classifier model with the parameters max_depth:5, max_leaf_nodes:10, and min_sample_leaf:25 is 0.87.\n",
    "Accuarcy has been increased after hyper parameter tuning. But it is still less than the accuracy of decision tree wiht a difference of 0.03. Ensemble methods are basically used to compute large datasets and the dataset on which we computing the model has 1000 rows only. So, there is a chance of underfitting. Decision tree classifier is weak learner because of only one tree. And there is a high cahance of overfitting and variance."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4- Explain how the GridSearchCV works."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will be doing hyperparameter tuning using gridsearch cv which is imported form sklearn model selection library. It basically a long nested for-loop which is simplified into few lines of code. Rather than going for nested for-loop to get which combination of hyperparameter values gives best accuracy values, we input all these into param_grid, parameter of the grid searchcv. By specifying the model name in estimator. It calculates the specified scoring parameter using it. It gives all the best parameters which gives best accuracy."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5- Repeat questions 1 to 3 above using the XGBoost ensembel of your choice inplace of the random forest and compare your results. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cross val score for n_estimator =  5 is 0.91625\n",
      "\n",
      "cross val score for n_estimator =  7 is 0.9175\n",
      "\n",
      "cross val score for n_estimator =  9 is 0.91875\n",
      "\n",
      "cross val score for n_estimator =  11 is 0.9175\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from xgboost import XGBClassifier\n",
    "for i in [5,7,9,11]:\n",
    "    clf_XG = XGBClassifier(n_estimators = i, random_state=590)\n",
    "    scores=cross_val_score(clf_XG,X_train,y_train,cv=4).mean()\n",
    "    print(\"cross val score for n_estimator = \", i, \"is\", scores)\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We are importing XGBClassifier from the xgboost library. It is called Extreme Gradient Boosting, and a ensembe method which comes under boosting(sequential) technique. In boosting, trees are built one after the other and performance of model is improved by assigning weightage to the previously incorrect classified samples.\n",
    "\n",
    "In Gradient Boosting, present base learner is  always more effective than the previous one and the base learners are generated in that way. Overall model performance improves sequentially with each iteration.\n",
    "\n",
    "XGBoost is an advance level of gradient boosting. It mainly focuses on computational speed and efficiency. This method optimizes the loss function of previos learner to increase the model performance.\n",
    "\n",
    "Using same techniques as in step-1, we are calculating cross validation score for training and validation datasets with 4 folds. By this we can determine number trees to be generated to procure the best accuracy from the model.\n",
    "\n",
    "For n_estimator = 9 the accuracy is 0.919"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#print('accuracy for 5,7,9,11 trees are',acc[0:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.875"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_XG = XGBClassifier(n_estimators= 9)\n",
    "model_XG.fit(X_train,y_train)\n",
    "y_pred_test_set = model_XG.predict(test_df)\n",
    "accuracy_score(y_test,y_pred_test_set)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We use the same estimator and build the model to find the predicting accuracy of test data. Accuracy for training and validating data is 0.919 and for the test data is 0.875. It can be because the model has not seen the test data and may behave differently with the test data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "params= {'max_depth': (3,4,5),\n",
    "        'max_leaf_nodes':(10,15,20),\n",
    "        'min_samples_leaf':(10,15,20,25)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test score is 0.895\n",
      "Best parameters:{'max_depth': 4, 'max_leaf_nodes': 10, 'min_samples_leaf': 10}\n",
      "Best grid search score:0.9137121830794214\n",
      "Best estimator:XGBClassifier(max_depth=4, max_leaf_nodes=10, min_samples_leaf=10,\n",
      "              n_estimators=11, random_state=590)\n"
     ]
    }
   ],
   "source": [
    "grid_search_XG = GridSearchCV(XGBClassifier(n_estimators = 11, random_state = 590), param_grid = params,return_train_score=True, n_jobs = -1, cv=3)\n",
    "grid_search_XG = grid_search_XG.fit(X_train, y_train)\n",
    "print(\"Test score is \"+str(grid_search_XG.score(test_df,y_test)))\n",
    "print(\"Best parameters:\"+str(grid_search_XG.best_params_))\n",
    "print(\"Best grid search score:\"+str(grid_search_XG.best_score_))\n",
    "print(\"Best estimator:\"+str(grid_search_XG.best_estimator_))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using the best model from the previous step, we are performing hyperparameter tuning of the model using gridsearchcv method.\n",
    "So for the combination max_depth:4, max_leaf_nodes:10, and min_sample_leaf:10 the accuracy is 0.914. And the accuracy has been improved after the parameter tuning.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYIAAAEJCAYAAACZjSCSAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjEsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+j8jraAAAd9klEQVR4nO3deZxVdf3H8dd7ZkBAUEAGlEUHFU3cc9RSTM1StHL5mQkuqJmoPynNcksxU9MWKy0txN1yCXMJ/blGLiFZDgoCKYGigmwDguKGwnx+f5wzeBnuzFxw7iyc9/PxuI85y/ee8z1w7n3f8/2eRRGBmZllV0lLV8DMzFqWg8DMLOMcBGZmGecgMDPLOAeBmVnGOQjMzDLOQWDWxkiqkBSSylq6LrZ+cBBYmyTpKUlLJG3Q0nUpBkn7SaqR9J6kZZKmSzppHZZziaQ/FaOOtv5wEFibI6kC2AcI4NBmXndz/gqfGxGdgY2A84AbJA1sxvVbRjgIrC0aBjwH3AqckDtDUj9J90mqlrRY0rU5806R9HL6C/s/kj6fTg9JW+eUu1XS5enwfpLmSDpP0nzgFkndJD2UrmNJOtw35/3dJd0iaW46/4F0+lRJ38gp107SIkm7NLSxkXgAWAKsEQSSeksaK+ltSTMlnZJOHwz8CDg6PbKYXOC/r2WM2xitLRoG/Br4F/CcpF4RsUBSKfAQ8HfgeGAlUAkg6SjgEuBwoArYCvikwPVtCnQHtiD58dQJuAX4FlAK3Axcmy4b4I/Ae8D26d+90um3A8cBD6bjhwDzImJSQyuXVAIcBnQFpuQpchcwDegNfA54QtJrEfGopCuArSPiuAK31TLIQWBtiqRBJF/IYyJikaRXgWOA3wB7kHwZnhMRK9K3jE//fgf4RUQ8n47PXIvV1gA/jojl6fiHwL05dfop8GQ6vBlwMLBJRCxJizyd/v0TMFLSRhHxLklY/bGB9faWtDRd/5vA8RExPW0aq113P2AQ8PWI+AiYJOnGdNnj1mIbLcPcNGRtzQnA4xGxKB2/k0+bh/oBb+SEQK5+wKvruM7q9EsWAEmdJF0v6Q1J7wLPAF3TI5J+wNs5IbBKRMwFngWOlNSVJDDuaGC9cyOia0R0j4hdIuLuPGV6p+tbljPtDaDPWm+lZZaPCKzNkNSRtDkmba8H2IDkS3hnYDawuaSyPGEwm6Q5KJ8PSJp7am0KzMkZr3uL3h8A2wJ7RsT8tI3/RUDperpL6hoRS/Os6zaSo5My4J8R8Vb9W1yQuen6uuSEweZA7XJ9e2FrlI8IrC05nKTdfyCwS/raDvgHSb/Bv4F5wM8kbSipg6S90/feCPxQ0m5KbC1pi3TeJOAYSaVpB+u+jdSjC0nz0FJJ3YEf186IiHnAI8Dv007ldpK+lPPeB4DPA2eS9Bl8JhExG5gAXJlu707AyXx6pLEAqEj7Gczy8s5hbckJwC0R8WZEzK99kXTUHkvyi/wbwNYkbepzgKMBIuIe4KckTUnLSL6Qu6fLPTN939J0OQ80Uo+rgY7AIpKzlx6tM/94ko7oV4CFwFm1MyKitn+hP3Df2m1+vYYCFSRHB/eT9Gc8kc67J/27WNILTbQ+W8/ID6Yxa16SLga28Zk81lq4j8CsGaVNSSeTHDWYtQpuGjJrJumFXrOBRyLimZauj1ktNw2ZmWWcjwjMzDKuzfUR9OjRIyoqKlq6GmZmbcrEiRMXRUR5vnltLggqKiqoqqpq6WqYmbUpkt6ob56bhszMMs5BYGaWcQ4CM7OMcxCYmWWcg8DMLOMcBGZmGecgMDPLOAeBmVnGOQjMzDKuzV1ZbGZrb/TE0S1dBWsCw3cbXpTlOgjMrFWYOmEqY64aQ01NDYMOH8TgEwevNv/9d9/n9ktvp3pONe3at2PYxcPos3WfVfNrVtZwxfFX0LVnV0ZcPQKA0ReMZsEbCwD4cNmHdOzSkZF3jmTR3EVcctQl9NqiFwBb7rAlx/7o2Gba0tbHQWBmLa5mZQ13/fwuzrruLLr16saVw65kpy/tRO8te68q88gtj9B3m76cftXpzH99Pnf+/E7O/sPZq+aPu2scm/bflI/e/2jVtOFXfvoL+p7f3EPHzh1XjZf3KWfknSOLvGVtg/sIzKzFzZo2i579elLet5yydmVUHljJ5Kcnr1Zm3mvz2G6P7QDYtGJTFs9dzLuL3wVgyYIlTHl2CoMOH5R3+RHBxL9NZPeDdi/uhrRRDgIza3FLFy6lW69uq8a79ezG0oVLVyvTd5u+vPD3FwCYNXUWb89/myULlwAw5ldjOPJ7RyIp7/JnvDiDLt270GvzXqumLZq7iMuPuZyrhl/FjBdnNPUmtSkOAjNrnep8pw8+YTAfLPuAy465jCf//CT9tu1HSWkJL/3jJbp078IW221R76Kef+x59jhoj1XjG/fYmCsfupKL7ryIo75/FDdddBMfvvdhsbak1XMfgZm1uK49u7JkwZJV40sWLqFredfVynTs3JETf3wikDT1XHjohfTo3YOqx6uY/Mxkpj47lU8+/oQP3/uQm0bexMmXnQzAyhUrefHJF7nwjxeuWla79u1o174dAFtstwXlfcpZ8OYCKgZWFHdDWykHgZm1uIqBFSycvZBFby2ia8+uVD1excmXn7xamQ+WfUD7Du0pa1fG+AfGM2DXAXTs3JEjRhzBESOOAGB61XSe+NMTq0IA4OV/v8ymFZuu1vS0bMkyNtxoQ0pKS6ieU83C2Qsp75P34V2Z4CAwsxZXWlbKkHOGcM13r6FmZQ17H7o3vbfqzdN/eRqAfb+5L/NmzePWH9+KSsRmW27GsJHDClp21eNV7H7g6p3EM16Ywdjrx1JaWopKxDEXHMOGG2/Y5NvVVigiWroOa6WysjL8qEqzteMLytYPn+WCMkkTI6Iy3zx3FpuZZVy2moZG+1fRemN4cS61N8uibAVBG/To1KmcOWYMK2tq+M6gQZw/ePXL7t/58EOOu+km3lyyhBUrV/LDr36Vk/beG4Brxo3jhvHjiQhOGTSIs77yFQAuefBBbhg/nvLOnQG44vDDOWTHHZt3w8ys1XAQtGIra2o44667eOKss+jbrRu7X3klh+60EwN7f3rZ/XVPPsnAzTbjwREjqF62jG0vvphj99yT/y5YwA3jx/PvCy6gfWkpg3/7W762444M6JVcUPP9Aw7ghwce2FKbZmatiPsIWrF/z5rF1j17smV5Oe3LyhhSWclfJ69+2b0kli1fTkTw3vLldN9wQ8pKSnh5/ny+0L8/ndq3p6y0lH232Yb7J01qoS0xs9bMQdCKvbV0Kf26fXruc99u3Xhr6eqX3Y/Yf39enjeP3ueey46XXso1Rx9NSUkJO/TuzTMzZrD4vff44OOPeXjKFGa//faq91371FPsdOmlfPu221jy/vvNtk1m1vq4aagVy3dib907qTw2bRq79OvH388+m1erq/nq1Vezz9Zbs91mm3HeQQfx1auvpvMGG7Bzv36UlZYCcPq++zLya19DwMixY/nBX/7CzSecUOzNMbNWykcErVjfrl2ZveTTy+7nLFlC766rX3Z/y4QJ/M+uuyKJrXv2pH+PHrwyfz4AJw8axAsXXcQz55xD906dGNCzJwC9NtqI0pISSkpKOGXQIP79+uvNtk1m1vo4CFqx3SsqmLFwIbMWLeLjFSu4u6qKQ3feebUym3fvzrhXXgFgwbvvMn3BArYsTy6VX/hucoveN99+m/tefJGhuydXV857551V779/0iR2yOl8NrPscdNQK1ZWWsq1Q4Zw0DXXsLKmhm/vvTfb9+7NqKeTy+5PS5t4Trz1Vnb8yU8I4OdHHEGP9LTQI6+/nsXvv0+70lKuGzqUbhsml9Cfe++9TJo9G0lUbLIJ1x93XEttopm1Atm6xYQvKFt/+IKyteJbTKwffIsJMzMrCgeBmVnGOQjMzDLOQWBmlnEOAjOzjHMQmJllnIPAzCzjHARmZhlX1CCQNFjSdEkzJZ2fZ/7Gkh6UNFnSNEknFbM+Zma2pqIFgaRS4DrgYGAgMFTSwDrFzgD+ExE7A/sBv5LUvlh1MjOzNRXziGAPYGZEvBYRHwN3A4fVKRNAF0kCOgNvAyuKWCczM6ujmEHQB5idMz4nnZbrWmA7YC4wBTgzImrqLkjScElVkqqqq6uLVV8zs0wqZhDUfYYKrPmslYOASUBvYBfgWkkbrfGmiNERURkRleXpLZbNzKxpFDMI5gD9csb7kvzyz3UScF8kZgKzgM8VsU5mZlZHMYPgeWCApP5pB/AQYGydMm8CBwBI6gVsC7xWxDqZmVkdRXswTUSskDQCeAwoBW6OiGmSTkvnjwIuA26VNIWkKem8iFhUrDqZmdmaivqEsoh4GHi4zrRROcNzgQOLWQczM2uYryw2M8s4B4GZWcY5CMzMMs5BYGaWcQ4CM7OMcxCYmWWcg8DMLOMcBGZmGecgMDPLOAeBmVnGOQjMzDLOQWBmlnEOAjOzjHMQmJllnIPAzCzjHARmZhnnIDAzyzgHgZlZxjkIzMwyzkFgZpZxDgIzs4xzEJiZZZyDwMws4xwEZmYZ5yAwM8s4B4GZWcY5CMzMMs5BYGaWcQ4CM7OMcxCYmWWcg8DMLOMcBGZmGecgMDPLOAeBmVnGOQjMzDKuqEEgabCk6ZJmSjq/njL7SZokaZqkp4tZHzMzW1OjQSBpb0kbpsPHSfq1pC0KeF8pcB1wMDAQGCppYJ0yXYHfA4dGxPbAUeuwDWZm9hkUckTwB+ADSTsD5wJvALcX8L49gJkR8VpEfAzcDRxWp8wxwH0R8SZARCwsuOZmZtYkCgmCFRERJF/i10TENUCXAt7XB5idMz4nnZZrG6CbpKckTZQ0LN+CJA2XVCWpqrq6uoBVm5lZocoKKLNM0gXA8cA+aZNPuwLepzzTIs/6dwMOADoC/5T0XET8d7U3RYwGRgNUVlbWXYaZmX0GhRwRHA0sB74dEfNJftX/soD3zQH65Yz3BebmKfNoRLwfEYuAZ4CdC1i2mZk1kUaDIP3yvxfYIJ20CLi/gGU/DwyQ1F9Se2AIMLZOmb+SHGWUSeoE7Am8XGjlzczss2u0aUjSKcBwoDuwFckRwSiS5px6RcQKSSOAx4BS4OaImCbptHT+qIh4WdKjwEtADXBjREz9LBtkZmZrp5A+gjNIzgD6F0BEzJDUs5CFR8TDwMN1po2qM/5LCmtqMjOzIiikj2B5evonAJLKWLPT18zM2qhCguBpST8COkr6KnAP8GBxq2VmZs2lkCA4H6gGpgCnkjT1XFTMSpmZWfNptI8gImqAG9KXmZmtZ+oNAkljIuJbkqaQp08gInYqas3MzKxZNHREcGb69+vNUREzM2sZ9QZBRMxLB0uAeRHxEYCkjkCvZqibmZk1g0I6i+8hudir1sp0mpmZrQcKCYKy3OsI0uH2xauSmZk1p0KCoFrSobUjkg4jud+QmZmtBwq5xcRpwB2SriW5tfRsIO9zA8zMrO0p5DqCV4EvSOoMKCKWFb9aZmbWXAo5IkDS14DtgQ5S8ryZiLi0iPUyM7NmUsjD60eRPJzmuyRNQ0cBjT683szM2oZCOov3iohhwJKI+AnwRVZ/8piZmbVhhQTBR+nfDyT1Bj4B+hevSmZm1pwK6SN4UFJXkofHvEBy3yHfgM7MbD3RYBBIKgHGRcRS4F5JDwEdIuKdZqmdmZkVXYNNQ+ktqH+VM77cIWBmtn4ppI/gcUlHqva8UTMzW68U0kdwNrAhsELSRySnkEZEbFTUmpmZWbMo5MriLs1RETMzaxmNBoGkL+WbHhHPNH11zMysuRXSNHROznAHYA9gIvDlotTIzMyaVSFNQ9/IHZfUD/hF0WpkZmbNqpCzhuqaA+zQ1BUxM7OWUUgfwe9IriaGJDh2ASYXs1JmZtZ8CukjqMoZXgHcFRHPFqk+ZmbWzAoJgr8AH0XESgBJpZI6RcQHxa2amZk1h0L6CMYBHXPGOwJ/K051zMysuRUSBB0i4r3akXS4U/GqZGZmzamQIHhf0udrRyTtBnxYvCqZmVlzKqSP4CzgHklz0/HNSB5daWZm64FCLih7XtLngG1Jbjj3SkR8UvSamZlZsyjk4fVnABtGxNSImAJ0lvS/hSxc0mBJ0yXNlHR+A+V2l7RS0jcLr7qZmTWFQvoITkmfUAZARCwBTmnsTZJKgeuAg4GBwFBJA+sp93PgsUIrbWZmTaeQICjJfShN+sXdvoD37QHMjIjXIuJj4G7gsDzlvgvcCywsYJlmZtbECgmCx4Axkg6Q9GXgLuCRAt7XB5idMz4nnbaKpD7AEcCohhYkabikKklV1dXVBazazMwKVUgQnEdyUdnpwBnAS6x+gVl98j3aMuqMXw2cV3vVcn0iYnREVEZEZXl5eQGrNjOzQhVy1lCNpOeALUlOG+1O0pTTmDlAv5zxvsDcOmUqgbvTlqcewCGSVkTEAwUs38zMmkC9QSBpG2AIMBRYDPwZICL2L3DZzwMDJPUH3kqXdUxugYjon7O+W4GHHAJmZs2roSOCV4B/AN+IiJkAkr5f6IIjYoWkESR9DKXAzRExTdJp6fwG+wXMzKx5NBQER5L8in9S0qMkZ/3ka/evV0Q8DDxcZ1reAIiIE9dm2WZm1jTq7SyOiPsj4mjgc8BTwPeBXpL+IOnAZqqfmZkVWaNnDUXE+xFxR0R8naTDdxJQ71XCZmbWtqzVM4sj4u2IuD4ivlysCpmZWfNal4fXm5nZesRBYGaWcQ4CM7OMcxCYmWWcg8DMLOMcBGZmGecgMDPLOAeBmVnGOQjMzDLOQWBmlnEOAjOzjHMQmJllnIPAzCzjHARmZhnnIDAzyzgHgZlZxjkIzMwyzkFgZpZxDgIzs4xzEJiZZZyDwMws4xwEZmYZ5yAwM8s4B4GZWcY5CMzMMs5BYGaWcQ4CM7OMcxCYmWWcg8DMLOMcBGZmGecgMDPLOAeBmVnGFTUIJA2WNF3STEnn55l/rKSX0tcESTsXsz5mZramogWBpFLgOuBgYCAwVNLAOsVmAftGxE7AZcDoYtXHzMzyK+YRwR7AzIh4LSI+Bu4GDsstEBETImJJOvoc0LeI9TEzszyKGQR9gNk543PSafU5GXgk3wxJwyVVSaqqrq5uwiqamVkxg0B5pkXegtL+JEFwXr75ETE6IiojorK8vLwJq2hmZmVFXPYcoF/OeF9gbt1CknYCbgQOjojFRayPmZnlUcwjgueBAZL6S2oPDAHG5haQtDlwH3B8RPy3iHUxM7N6FO2IICJWSBoBPAaUAjdHxDRJp6XzRwEXA5sAv5cEsCIiKotVJzMzW1Mxm4aIiIeBh+tMG5Uz/B3gO8Wsg5mZNcxXFpuZZZyDwMws4xwEZmYZ5yAwM8s4B4GZWcY5CMzMMs5BYGaWcQ4CM7OMcxCYmWWcg8DMLOMcBGZmGecgMDPLOAeBmVnGOQjMzDLOQWBmlnEOAjOzjHMQmJllnIPAzCzjHARmZhnnIDAzyzgHgZlZxjkIzMwyzkFgZpZxDgIzs4xzEJiZZZyDwMws4xwEZmYZ5yAwM8s4B4GZWcY5CMzMMs5BYGaWcQ4CM7OMcxCYmWWcg8DMLOMcBGZmGVfUIJA0WNJ0STMlnZ9nviT9Np3/kqTPF7M+Zma2pqIFgaRS4DrgYGAgMFTSwDrFDgYGpK/hwB+KVR8zM8uvmEcEewAzI+K1iPgYuBs4rE6Zw4DbI/Ec0FXSZkWsk5mZ1VFWxGX3AWbnjM8B9iygTB9gXm4hScNJjhgA3pM0vWmrul7pASxq6UoU3amntnQNrPVZ7/f9U/lM+/0W9c0oZhAoz7RYhzJExGhgdFNUan0nqSoiKlu6HmbNzfv+uitm09AcoF/OeF9g7jqUMTOzIipmEDwPDJDUX1J7YAgwtk6ZscCw9OyhLwDvRMS8ugsyM7PiKVrTUESskDQCeAwoBW6OiGmSTkvnjwIeBg4BZgIfACcVqz4Z4iY0yyrv++tIEWs0yZuZWYb4ymIzs4xzEJiZZZyDwMws4xwEjZC0iaRJ6Wu+pLdyxtsX8P79JO3VSJm/Svpn09W6+UkaK+n4nPEbJJ2TDpdJukLSjJx/uwtbrrZWn8+yv0uqlPTbdVjnrpJC0kHrXvOWlW771Np/I0lbSXpN0kbp+B6Snko/Ay9I+j9JO7ZsrT/lzuK1IOkS4L2IuKqp3iOpKzAFeA84JCJmNUFV862nLCJWFGPZ6fIrgCeBXUnuLTUK2C0iPpH0M2BT4LSI+EhSF+AHEXFJsepjn12+fbcY+5GkXwBfBF6NiBObctl11lMaESuLuPzfA3Mi4gpJjwK3RcRdknoB/wKOiYgJadlBQI+IeKBY9VkrEeFXgS/gEuCHwG7A08BEktNjN0vnfw/4D/ASyb2VKoD5wFvAJGCfPMs8Gfg98GPggpzpWwN/AyYDLwBbpdPPJQmOycDP0mlPAZXpcA/g9XT4ROAe4EHg70BnYFy6vCnAYTnrG5bWezLwR6ALMAtol87fCHi9dryef58LSE7hmwR8KZ3WCVgMdGnp/z+/1nl/vxX4NUnQ/4rkPmITgBfTv9um5fcDHsp5783pvvka8L161qF0/lYkF5N2yJmXb19f43ORu960zLXAienw68DFwHiSa5lOIbnGaTJwL9ApLdcLuD+dPhnYC7gMODNnuT+tbzvS+V3TbTkXGJcz/TLgJy39/9ng/3VLV6AtvdKd+5x05y9Ppx1Nco0E6Y68Qe1OkfOeHzawzL8B+wDbAC/lTP8XcEQ63CH9Qj04XXftzts9/fsU9QfBnJxyZcBGOeVmph/E7YHpJL9Qcpd7C3B4Ojwc+FUj/z7tgDeBO3Km7QS82NL/d36t8/5eGwQPAaXp9I2AsnT4K8C96fCqL+T0vROADdJ9bTF5fkQAg2q/NIE7gf9Jh+vb1/N9LlatN51eNwjOzZm3Sc7w5cB30+E/A2elw6XAxiQ/5F5Ip5UAr+a+v55/s1OBlaThmE67j5wfXa3xVcx7Da2vNgB2AJ6QBMlOU3s19EvAHZIeABo95EsPGbcGxkdESFohaQfgDaBPRNwPEBEfpeW/AtwSER+k098uoL5P5JQTcIWkLwE1JDf46wV8GfhLRCyqs9wbSX7dPEBysd8pjaxrp3Qdn5NUEhE1ebb5JOBMYBNgr4iYXbeMtUr3xKfNKhsDt0kaQHJvsHb1vOf/ImI5sFzSQpJ9bU6dMkNJjp5J/x5P8sW5xr6eNinm+1w0Vvc/5wzvIOlykl/vnUmO6CH5DAxLl7sSeAd4R9JiSbumdX8xIhY3sq6DgQUkzaN5b44p6V8kYfp4RJzZWOWbgzuL156AaRGxS/raMSIOTOd9jeQZDLsBEyU1FrRHA92AWZJeJ/kFMoT8N+OrXXe+Tp0VfPp/2aHOvPdzho8Fykna7nch2WE71LfciHgWqJC0L8mvwan1bYikEpImruOBGcDp6ayZwObph5iIuCVd9zskIWptQ+5+dBnwZETsAHyDNfe5WstzhldS504G6TNLjgQuTvf/3wEHp/tKvn2yvs9F7v5Pnvrk1v1WYERE7Aj8pIG617qR5Mj6JJKmrnpJ+jpJSB4E/FJSp3TWNGDVQ7ciYk9gZFq2VXAQrL3lQLmkLwJIaidp+/SLsF9EPEnyK7r2F8cykvb2fIYCgyOiIiIqSAJkSES8C8yRdHi6jg3Snepx4Nu1O5ik7ulyXk/fC/DNBuq+MbAwkg7c/fn0trTjgG9J2qTOcgFuB+4iaSZqyKnAjIh4CjgbOFdSefqL7ibgWkkd0uWXAo2ecWWt1sYk/V6QfEmuq68AkyOiX/oZ2IKk3f5w8uzrDXwu3gAGpuMbAwc0sM4uwDxJ7Uh+GNUaR/rjRVJp7dk+JP0Gg4Hd+fToYQ2SOpL0n5wREVOAvwK1Z8ZdB5xY5+zBTrQiDoK1V0PyZftzSZNJOkb3Ivl1+ydJU0g60X4TEUtJOmqPSE+/26d2IelZNpsDz9VOi+SMoXcl7Unyy/p7kl4iaSvdNCIeJblRX5WkSSTttwBXAadLmkDSHlufO4BKSVUkH4JX0vVOI+kIezrdpl/XeU83kjDIS1JP4Lza+kTEXOAa4BdpkQtJms+mSnoR+AdwG77TbFv1C+BKSc/y2Y7qhpJ80ea6l+Tsmvr29Xyfi9nAGNKmWZLPX31GkvQzPEG6/6fOBPZPP78TSfrNiOShWk8CY6LhM45GAg9ExH/S8UuAIZIGRMR8kqP/K5U8lncCyXfItQ0sr1n59FFrkKRvknR0Hd9oYbP1THqk/wJwVETMaOn6FIs7i61ekn5H0vl1SEvXxay5KXnG+kPA/etzCICPCGwtSboO2LvO5GsiorE+BLM2L70a+I91Ji9PO4DbLAeBmVnGubPYzCzjHARmZhnnIDAzyzgHgZlZxv0/w8QGHB0+CO0AAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "            xgb = XGBClassifier(n_estimators = 11, max_depth = 4, max_leaf_nodes = 10, min_samples_leaf = 10, random_state = 590)\n",
    "            xgb.fit(X_train, y_train)  #fit the model\n",
    "            y_pred = xgb.predict(test_df)\n",
    "            testaccuracy_XG = accuracy_score(y_test,y_pred)  \n",
    "            \n",
    "            y_pred2 = xgb.predict(X_train)\n",
    "            trainaccuracy_XG = accuracy_score(y_train,y_pred2)\n",
    "            \n",
    "            objects_XG = ('Test Accuracy_XG', 'Train Accuracy_XG')\n",
    "            y = np.arange(len(objects_XG))\n",
    "            Accuracy_XG = [testaccuracy_XG, trainaccuracy_XG]\n",
    "            plt.bar(y, Accuracy_XG, width = 0.6, align = 'center', alpha=0.4, color = ['red', 'green'])\n",
    "            for index, value in enumerate(Accuracy_XG): \n",
    "                plt.text(index, value, str(value), horizontalalignment='center', verticalalignment='top', alpha = 1.0)\n",
    "            plt.xticks(y, objects_XG)\n",
    "            plt.ylabel('Accuracies')\n",
    "            plt.title('Accuracy Plot')\n",
    "            plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, we are using best parameters from the gridsearch cv to evaluate the predicting accuracy of training data and predicting accuracy for the test data.\n",
    "\n",
    "The prediction accuracy of test data for decision tree model with the parameters max_depth:3, max_leaf_nodes:15, and min_sample_leaf:10 is 0.9.\n",
    "\n",
    "The prediction accuracy of test data for XGBosst classifier model with the parameters max_depth:4, max_leaf_nodes:10, and min_sample_leaf:10 is 0.895. There is a slight decrease in the performance but there can be much better accuracy if the model is trained with much more data. Since, these ensemble methods are used to compute large datasets. There can be an issue of underfitting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
